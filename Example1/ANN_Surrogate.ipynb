{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.5808 - acc: 0.7316     \n",
      "Epoch 2/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.3958 - acc: 0.8574     \n",
      "Epoch 3/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.3338 - acc: 0.8827     \n",
      "Epoch 4/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.2894 - acc: 0.8981     \n",
      "Epoch 5/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.2431 - acc: 0.9175     \n",
      "Epoch 6/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.2123 - acc: 0.9308     \n",
      "Epoch 7/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.1861 - acc: 0.9384     \n",
      "Epoch 8/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.1680 - acc: 0.9449     \n",
      "Epoch 9/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.1403 - acc: 0.9567     \n",
      "Epoch 10/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.1309 - acc: 0.9595     \n",
      "Epoch 11/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.1210 - acc: 0.9654     \n",
      "Epoch 12/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.1176 - acc: 0.9664     \n",
      "Epoch 13/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.1010 - acc: 0.9723     \n",
      "Epoch 14/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0941 - acc: 0.9726     \n",
      "Epoch 15/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0872 - acc: 0.9752     \n",
      "Epoch 16/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0888 - acc: 0.9746     \n",
      "Epoch 17/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0777 - acc: 0.9779     \n",
      "Epoch 18/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0795 - acc: 0.9767     \n",
      "Epoch 19/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0798 - acc: 0.9770     \n",
      "Epoch 20/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0754 - acc: 0.9792     \n",
      "Epoch 21/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0713 - acc: 0.9796     \n",
      "Epoch 22/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0714 - acc: 0.9795     \n",
      "Epoch 23/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0645 - acc: 0.9817     \n",
      "Epoch 24/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0657 - acc: 0.9811     \n",
      "Epoch 25/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0679 - acc: 0.9789     \n",
      "Epoch 26/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0607 - acc: 0.9840     \n",
      "Epoch 27/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0555 - acc: 0.9851     \n",
      "Epoch 28/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0544 - acc: 0.9853     \n",
      "Epoch 29/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0583 - acc: 0.9846     \n",
      "Epoch 30/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0534 - acc: 0.9847     \n",
      "Epoch 31/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0542 - acc: 0.9865     \n",
      "Epoch 32/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0552 - acc: 0.9854     \n",
      "Epoch 33/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0522 - acc: 0.9863     \n",
      "Epoch 34/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0544 - acc: 0.9870     \n",
      "Epoch 35/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0503 - acc: 0.9866     \n",
      "Epoch 36/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0495 - acc: 0.9873     \n",
      "Epoch 37/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0504 - acc: 0.9868     \n",
      "Epoch 38/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0551 - acc: 0.9841     \n",
      "Epoch 39/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0458 - acc: 0.9883     \n",
      "Epoch 40/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0484 - acc: 0.9876     \n",
      "Epoch 41/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0480 - acc: 0.9867     \n",
      "Epoch 42/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0553 - acc: 0.9849     \n",
      "Epoch 43/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0400 - acc: 0.9899     \n",
      "Epoch 44/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0525 - acc: 0.9868     \n",
      "Epoch 45/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0453 - acc: 0.9876     \n",
      "Epoch 46/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0499 - acc: 0.9868     \n",
      "Epoch 47/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0507 - acc: 0.9868     \n",
      "Epoch 48/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0477 - acc: 0.9886     \n",
      "Epoch 49/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0421 - acc: 0.9890     \n",
      "Epoch 50/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0420 - acc: 0.9901     \n",
      "Epoch 51/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0425 - acc: 0.9884     \n",
      "Epoch 52/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0443 - acc: 0.9882     \n",
      "Epoch 53/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0415 - acc: 0.9899     \n",
      "Epoch 54/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0451 - acc: 0.9891     \n",
      "Epoch 55/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0358 - acc: 0.9916     \n",
      "Epoch 56/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0395 - acc: 0.9902     \n",
      "Epoch 57/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0424 - acc: 0.9896     \n",
      "Epoch 58/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0396 - acc: 0.9904     \n",
      "Epoch 59/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0409 - acc: 0.9897     \n",
      "Epoch 60/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0445 - acc: 0.9894     \n",
      "Epoch 61/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0345 - acc: 0.9920     \n",
      "Epoch 62/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0373 - acc: 0.9899     \n",
      "Epoch 63/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0388 - acc: 0.9898     \n",
      "Epoch 64/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0336 - acc: 0.9918     \n",
      "Epoch 65/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0348 - acc: 0.9916     \n",
      "Epoch 66/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0348 - acc: 0.9911     \n",
      "Epoch 67/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0431 - acc: 0.9901     \n",
      "Epoch 68/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0388 - acc: 0.9904     \n",
      "Epoch 69/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0414 - acc: 0.9897     \n",
      "Epoch 70/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0356 - acc: 0.9913     \n",
      "Epoch 71/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0368 - acc: 0.9915     \n",
      "Epoch 72/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0337 - acc: 0.9918     \n",
      "Epoch 73/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0388 - acc: 0.9908     \n",
      "Epoch 74/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0429 - acc: 0.9895     \n",
      "Epoch 75/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0387 - acc: 0.9910     \n",
      "Epoch 76/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0365 - acc: 0.9913     \n",
      "Epoch 77/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0401 - acc: 0.9912     \n",
      "Epoch 78/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0384 - acc: 0.9909     \n",
      "Epoch 79/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0366 - acc: 0.9916     \n",
      "Epoch 80/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0398 - acc: 0.9901     \n",
      "Epoch 81/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0344 - acc: 0.9912     \n",
      "Epoch 82/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0341 - acc: 0.9915     \n",
      "Epoch 83/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0365 - acc: 0.9906     \n",
      "Epoch 84/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0464 - acc: 0.9888     \n",
      "Epoch 85/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0340 - acc: 0.9916     \n",
      "Epoch 86/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0348 - acc: 0.9917     \n",
      "Epoch 87/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0384 - acc: 0.9918     \n",
      "Epoch 88/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0437 - acc: 0.9910     \n",
      "Epoch 89/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0347 - acc: 0.9918     \n",
      "Epoch 90/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0368 - acc: 0.9908     \n",
      "Epoch 91/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0362 - acc: 0.9921     \n",
      "Epoch 92/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0391 - acc: 0.9899     \n",
      "Epoch 93/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0363 - acc: 0.9901     \n",
      "Epoch 94/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0334 - acc: 0.9924     \n",
      "Epoch 95/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0340 - acc: 0.9921     \n",
      "Epoch 96/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0357 - acc: 0.9913     \n",
      "Epoch 97/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0376 - acc: 0.9911     \n",
      "Epoch 98/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0318 - acc: 0.9926     \n",
      "Epoch 99/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0329 - acc: 0.9924     \n",
      "Epoch 100/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0397 - acc: 0.9899     \n",
      "Epoch 101/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0391 - acc: 0.9911     \n",
      "Epoch 102/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0353 - acc: 0.9913     \n",
      "Epoch 103/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0379 - acc: 0.9909     \n",
      "Epoch 104/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0377 - acc: 0.9914     \n",
      "Epoch 105/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0293 - acc: 0.9928     \n",
      "Epoch 106/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0316 - acc: 0.9926     \n",
      "Epoch 107/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0343 - acc: 0.9917     \n",
      "Epoch 108/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0313 - acc: 0.9916     \n",
      "Epoch 109/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0352 - acc: 0.9920     \n",
      "Epoch 110/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0333 - acc: 0.9926     \n",
      "Epoch 111/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0332 - acc: 0.9924     \n",
      "Epoch 112/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0367 - acc: 0.9908     \n",
      "Epoch 113/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0378 - acc: 0.9911     \n",
      "Epoch 114/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0375 - acc: 0.9909     \n",
      "Epoch 115/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0352 - acc: 0.9920     \n",
      "Epoch 116/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0371 - acc: 0.9907     \n",
      "Epoch 117/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0366 - acc: 0.9916     \n",
      "Epoch 118/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0332 - acc: 0.9915     \n",
      "Epoch 119/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0358 - acc: 0.9914     \n",
      "Epoch 120/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0369 - acc: 0.9913     \n",
      "Epoch 121/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0332 - acc: 0.9916     \n",
      "Epoch 122/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0320 - acc: 0.9924     \n",
      "Epoch 123/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0337 - acc: 0.9917     \n",
      "Epoch 124/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0315 - acc: 0.9927     \n",
      "Epoch 125/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0278 - acc: 0.9934     \n",
      "Epoch 126/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0369 - acc: 0.9911     \n",
      "Epoch 127/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0350 - acc: 0.9919     \n",
      "Epoch 128/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0315 - acc: 0.9925     \n",
      "Epoch 129/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0333 - acc: 0.9916     \n",
      "Epoch 130/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0306 - acc: 0.9931     \n",
      "Epoch 131/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0306 - acc: 0.9926     \n",
      "Epoch 132/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0266 - acc: 0.9936     \n",
      "Epoch 133/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0351 - acc: 0.9915     \n",
      "Epoch 134/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0309 - acc: 0.9927     \n",
      "Epoch 135/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0317 - acc: 0.9926     \n",
      "Epoch 136/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0287 - acc: 0.9934     \n",
      "Epoch 137/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0333 - acc: 0.9921     \n",
      "Epoch 138/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0368 - acc: 0.9918     \n",
      "Epoch 139/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0323 - acc: 0.9923     \n",
      "Epoch 140/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0319 - acc: 0.9927     \n",
      "Epoch 141/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0413 - acc: 0.9908     \n",
      "Epoch 142/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0322 - acc: 0.9924     \n",
      "Epoch 143/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0311 - acc: 0.9928     \n",
      "Epoch 144/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0361 - acc: 0.9913     \n",
      "Epoch 145/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0328 - acc: 0.9933     \n",
      "Epoch 146/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0382 - acc: 0.9918     \n",
      "Epoch 147/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0318 - acc: 0.9924     \n",
      "Epoch 148/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0330 - acc: 0.9923     \n",
      "Epoch 149/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0293 - acc: 0.9931     \n",
      "Epoch 150/150\n",
      "16000/16000 [==============================] - 0s - loss: 0.0339 - acc: 0.9919     \n",
      "4000/4000 [==============================] - 0s     \n",
      "The score of your regression is\n",
      "[0.011619447002006268, 0.99775000000000003]\n",
      "[WARNING] model.h5 already exists - overwrite? [y/n]y\n",
      "[TIP] Next time specify overwrite=True in save_weights!\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# %reset\n",
    "## This code builds an ANN surrogate model for two-terminal connectivity.\n",
    "## Written by Mohammad Amin Nabian, mnabia2@illinois.edu, March 2017\n",
    "\n",
    "## Import libraries\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras import optimizers\n",
    "\n",
    "## Initialization\n",
    "nbridges=39\n",
    "\n",
    "## Generating the network topology\n",
    "G=nx.Graph()\n",
    "G.add_node(0)\n",
    "G.add_node(1)\n",
    "G.add_node(2)\n",
    "G.add_node(3)\n",
    "G.add_node(4)\n",
    "G.add_node(5)\n",
    "G.add_node(6)\n",
    "G.add_node(7)\n",
    "G.add_node(8)\n",
    "G.add_node(9)\n",
    "G.add_node(10)\n",
    "G.add_node(11)\n",
    "G.add_edge(0,1)\n",
    "G.add_edge(0,2)\n",
    "G.add_edge(1,3)\n",
    "G.add_edge(1,4)\n",
    "G.add_edge(2,3)\n",
    "G.add_edge(3,4)\n",
    "G.add_edge(2,6)\n",
    "G.add_edge(3,4)\n",
    "G.add_edge(3,5)\n",
    "G.add_edge(4,7)\n",
    "G.add_edge(6,7)\n",
    "G.add_edge(5,6)\n",
    "G.add_edge(5,8)\n",
    "G.add_edge(6,9)\n",
    "G.add_edge(7,8)\n",
    "G.add_edge(7,11)\n",
    "G.add_edge(8,10)\n",
    "G.add_edge(8,9)\n",
    "G.add_edge(9,10)\n",
    "G.add_edge(10,11)\n",
    "\n",
    "## Assign the failure probabilities\n",
    "s=(nbridges,2);b=np.zeros(s)\n",
    "b[0]=(0,1)\n",
    "b[1]=(0,2)\n",
    "b[2]=(0,2)\n",
    "b[3]=(0,2)\n",
    "b[4]=(0,2)\n",
    "b[5]=(0,2)\n",
    "b[6]=(0,2)\n",
    "b[7]=(1,3)\n",
    "b[8]=(1,4)\n",
    "b[9]=(1,4)\n",
    "b[10]=(2,3)\n",
    "b[11]=(2,3)\n",
    "b[12]=(2,3)\n",
    "b[13]=(2,3)\n",
    "b[14]=(2,3)\n",
    "b[15]=(2,3)\n",
    "b[16]=(2,6)\n",
    "b[17]=(2,6)\n",
    "b[18]=(2,6)\n",
    "b[19]=(2,6)\n",
    "b[20]=(3,4)\n",
    "b[21]=(3,4)\n",
    "b[22]=(3,4)\n",
    "b[23]=(3,5)\n",
    "b[24]=(3,5)\n",
    "b[25]=(4,7)\n",
    "b[26]=(5,6)\n",
    "b[27]=(5,6)\n",
    "b[28]=(7,8)\n",
    "b[29]=(7,11)\n",
    "b[30]=(7,11)\n",
    "b[31]=(7,11)\n",
    "b[32]=(7,11)\n",
    "b[33]=(8,10)\n",
    "b[34]=(8,10)\n",
    "b[35]=(9,10)\n",
    "b[36]=(9,10)\n",
    "b[37]=(9,10)\n",
    "b[38]=(9,10)\n",
    "\n",
    "# Import the data for surrogate\n",
    "fpb = np.loadtxt('SURVIVALS_Train.txt')\n",
    "nsamplesEQ = np.shape(fpb)[1]\n",
    "nsamplesMC = 10\n",
    "fpb_samples = np.zeros((nbridges,nsamplesEQ,nsamplesMC),dtype=int)\n",
    "for i in range (nbridges):\n",
    "    for j in range (nsamplesEQ):\n",
    "        for k in range (nsamplesMC):\n",
    "            if (np.random.rand() < 1. - fpb[i,j]):\n",
    "                fpb_samples[i,j,k] = 1   # bridge will fail\n",
    "\n",
    "def CONNECTIVITY_train (index):\n",
    "    connect_flag = np.zeros(nsamplesMC)\n",
    "    for p in range (nsamplesMC):\n",
    "        T=copy.deepcopy(G)\n",
    "        for i in range (nbridges):\n",
    "            if fpb_samples[i,index,p] == 1:\n",
    "                if T.has_edge(int(b[i,0]),int(b[i,1])):\n",
    "                    T.remove_edge(*b[i])\n",
    "        if nx.has_path(T,0,11):\n",
    "            connect_flag[p] = 1\n",
    "    del T\n",
    "    return connect_flag\n",
    "\n",
    "connect_matrix = Parallel(n_jobs=8)(delayed(CONNECTIVITY_train)(index) for index in range(nsamplesEQ))\n",
    "# np.shape(connect_matrix) = (nsamplesEQ,nsamplesMC)\n",
    "\n",
    "# Reshape\n",
    "X = np.zeros((nsamplesEQ*nsamplesMC,nbridges),dtype=int)\n",
    "for i in range (nbridges):\n",
    "    c = -1\n",
    "    for j in range (nsamplesEQ):\n",
    "        for k in range (nsamplesMC):\n",
    "            c += 1\n",
    "            X[c,i] = fpb_samples[i,j,k]\n",
    "            \n",
    "Y = np.zeros((nsamplesEQ*nsamplesMC,1),dtype=int)\n",
    "c = -1\n",
    "for j in range (nsamplesEQ):\n",
    "    for k in range (nsamplesMC):\n",
    "        c += 1\n",
    "        Y[c] = connect_matrix[j][k]\n",
    "\n",
    "# Perform the deep learning\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, Y, test_size=0.2)\n",
    "y_train, y_test = [np_utils.to_categorical(x) for x in (y_train, y_test)]\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim=128, input_shape=(nbridges,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(output_dim=64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(output_dim=32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(output_dim=16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(output_dim=8))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(output_dim=4))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(output_dim=2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=150, batch_size=64)\n",
    "deep_score = model.evaluate(X_test, y_test, batch_size=64)\n",
    "print('The score of your regression is')\n",
    "print(deep_score)\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "np.savetxt('samples_train.txt',X_train)\n",
    "np.savetxt('samples_test.txt',X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
